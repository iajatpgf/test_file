import streamlit as st

from langchain.memory import ConversationBufferMemory
from ut2 import qa_agent


st.title("ğŸ“‘ AIæ™ºèƒ½æ–‡æ¡£é—®ç­”å·¥å…·")

with st.sidebar:
    openai_api_key = st.text_input("è¯·è¾“å…¥OpenAI APIå¯†é’¥ï¼š", type="password")
    st.markdown("[è·å–OpenAI API key](https://platform.openai.com/account/api-keys)")
    st.subheader('è¯·é€‰æ‹©æ‰€è¦ä½¿ç”¨çš„æ¨¡å‹')
    "é»˜è®¤ä½¿ç”¨gpt-3.5æ¨¡å‹ï¼Œè‹¥æƒ³å¾—åˆ°æ›´å¥½çš„å›å¤ï¼Œè¯·é€‰æ‹©gpt-4oæ¨¡å‹"
    selected_model = st.sidebar.selectbox('é€‰æ‹©ä¸€ä¸ªæ¨¡å‹', ['gpt-3.5-turbo', 'gpt-4o'],
                                          key='selected_model')

if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(
        return_messages=True,
        memory_key="chat_history",
        output_key="answer"
    )

with st.sidebar:  # æ·»åŠ ä¸€ä¸ªæŒ‰é’®ï¼Œç‚¹å‡»åé‡æ–°è®¾ç½®ä¼šè¯çŠ¶æ€
    st.markdown('<p style="color:green; font-size: 24px;">æ›´æ¢æ–‡æ¡£åè¯·åˆ·æ–°ï¼ˆæŒ‰F5ï¼‰åå†æé—®</p>', unsafe_allow_html=True)

uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„æ–‡ä»¶ï¼Œæ”¯æŒWordï¼ŒExcelï¼ŒPowerPointï¼Œpdfï¼Œtxtï¼š", type=["pdf", "txt", "docx", "pptx", "xlsx"])
question = st.text_input("å¯¹æ–‡æ¡£çš„å†…å®¹è¿›è¡Œæé—®,æŒ‰å›è½¦é”®ç»“æŸ       \n ç¤ºä¾‹ï¼š'è¿™ä»½æ–‡ä»¶çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ'ï¼Œ'æ ¹æ®è¿™ä»½æ–‡ä»¶ï¼Œå†™ä¸€ä»½é¡¹ç›®è®¡åˆ’ã€‚'", disabled=not uploaded_file)

if uploaded_file and question and not openai_api_key:
    st.info("è¯·è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥")

if uploaded_file and question and openai_api_key:
    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
        response = qa_agent(selected_model, openai_api_key, st.session_state["memory"],
                            uploaded_file, question)
    st.write("### ç­”æ¡ˆ")
    st.write(response["answer"])
    st.session_state["chat_history"] = response["chat_history"]

if "chat_history" in st.session_state:
    with st.expander("å†å²æ¶ˆæ¯"):
        for i in range(0, len(st.session_state["chat_history"]), 2):
            human_message = st.session_state["chat_history"][i]
            ai_message = st.session_state["chat_history"][i+1]
            st.write(human_message.content)
            st.write(ai_message.content)
            if i < len(st.session_state["chat_history"]) - 2:
                st.divider()
